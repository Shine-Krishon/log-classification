#!/usr/bin/env python3
"""
F1 Score Business Impact Analysis
================================

Demonstrate the real-world business value of F1 scores for log classification
"""

def analyze_business_impact():
    """
    Show the business impact of your model's F1 scores
    """
    print("üíº F1 SCORE BUSINESS IMPACT ANALYSIS")
    print("="*60)
    
    # Your model's current F1 scores
    model_performance = {
        'security_alert': 1.0000,
        'user_action': 0.9474, 
        'deprecation_warning': 0.8889,
        'workflow_error': 0.8889,
        'system_notification': 0.5714,
        'weighted_average': 0.8038
    }
    
    # Business cost estimates (per month for enterprise system)
    monthly_logs = 1_000_000  # 1M logs per month
    cost_per_false_positive = 150  # Analyst time cost
    cost_per_missed_threat = 50_000  # Average security incident cost
    
    print(f"\nüè¢ ENTERPRISE SYSTEM ASSUMPTIONS:")
    print(f"   ‚Ä¢ Monthly log volume: {monthly_logs:,} logs")
    print(f"   ‚Ä¢ Cost per false positive: ${cost_per_false_positive}")
    print(f"   ‚Ä¢ Cost per missed security threat: ${cost_per_missed_threat:,}")
    
    print(f"\nüéØ YOUR MODEL'S BUSINESS VALUE:")
    
    # Security Alert Analysis
    security_f1 = model_performance['security_alert']
    expected_security_logs = monthly_logs * 0.02  # 2% security logs
    
    if security_f1 == 1.0:
        missed_threats = 0
        threat_cost = 0
        print(f"   ‚úÖ Security Alerts (F1={security_f1:.3f}):")
        print(f"      ‚Ä¢ Missed threats: {missed_threats} (PERFECT!)")
        print(f"      ‚Ä¢ Monthly threat cost: ${threat_cost:,}")
    else:
        missed_threats = int(expected_security_logs * (1 - security_f1))
        threat_cost = missed_threats * cost_per_missed_threat
        print(f"   ‚ö†Ô∏è  Security Alerts (F1={security_f1:.3f}):")
        print(f"      ‚Ä¢ Missed threats: ~{missed_threats}")
        print(f"      ‚Ä¢ Monthly threat cost: ${threat_cost:,}")
    
    # User Action Analysis  
    user_f1 = model_performance['user_action']
    expected_user_logs = monthly_logs * 0.40  # 40% user action logs
    false_positives = int(expected_user_logs * (1 - user_f1))
    fp_cost = false_positives * cost_per_false_positive
    
    print(f"\n   ‚úÖ User Actions (F1={user_f1:.3f}):")
    print(f"      ‚Ä¢ False alarms: ~{false_positives:,}")
    print(f"      ‚Ä¢ Monthly false alarm cost: ${fp_cost:,}")
    
    # Total monthly savings vs poor model
    poor_model_security_f1 = 0.85  # Typical industry performance
    poor_model_user_f1 = 0.70
    
    poor_missed_threats = int(expected_security_logs * (1 - poor_model_security_f1))
    poor_threat_cost = poor_missed_threats * cost_per_missed_threat
    
    poor_false_positives = int(expected_user_logs * (1 - poor_model_user_f1))
    poor_fp_cost = poor_false_positives * cost_per_false_positive
    
    total_savings = (poor_threat_cost - threat_cost) + (poor_fp_cost - fp_cost)
    
    print(f"\nüí∞ MONTHLY COST SAVINGS vs TYPICAL MODEL:")
    print(f"   ‚Ä¢ Your model total cost: ${threat_cost + fp_cost:,}")
    print(f"   ‚Ä¢ Typical model cost: ${poor_threat_cost + poor_fp_cost:,}")
    print(f"   ‚Ä¢ Monthly savings: ${total_savings:,}")
    print(f"   ‚Ä¢ Annual savings: ${total_savings * 12:,}")
    
    return {
        'monthly_savings': total_savings,
        'annual_savings': total_savings * 12,
        'security_threats_prevented': poor_missed_threats - missed_threats,
        'false_alarms_reduced': poor_false_positives - false_positives
    }

def explain_f1_vs_accuracy():
    """
    Explain why F1 is better than accuracy for log classification
    """
    print(f"\nüìö WHY F1 SCORE > ACCURACY FOR LOG CLASSIFICATION")
    print("="*60)
    
    print("""
üéØ Scenario: 1000 log entries
   ‚Ä¢ 950 normal user activities  
   ‚Ä¢ 50 security alerts

‚ùå BAD MODEL (High Accuracy, Low F1):
   ‚Ä¢ Classifies everything as "user_action"
   ‚Ä¢ Accuracy: 95% (looks great!)
   ‚Ä¢ Security Alert F1: 0.0 (DISASTER!)
   ‚Ä¢ Result: All threats missed

‚úÖ YOUR MODEL (Balanced F1):
   ‚Ä¢ Security Alert F1: 1.0 (Perfect threat detection)
   ‚Ä¢ User Action F1: 0.95 (Minimal false alarms)
   ‚Ä¢ Result: Optimal business outcome

üîë Key Insight:
   F1 Score = 2 √ó (Precision √ó Recall) / (Precision + Recall)
   
   ‚Ä¢ HIGH PRECISION: When model says "security alert", it's right
   ‚Ä¢ HIGH RECALL: Model catches most/all real security alerts  
   ‚Ä¢ F1 BALANCES BOTH: Perfect for cybersecurity applications
    """)

def show_monitoring_thresholds():
    """
    Show how to use F1 scores for ongoing model monitoring
    """
    print(f"\nüìä F1 SCORE MONITORING THRESHOLDS")
    print("="*60)
    
    thresholds = {
        'security_alert': {
            'excellent': 0.95,
            'acceptable': 0.90,
            'critical': 0.85
        },
        'user_action': {
            'excellent': 0.90,
            'acceptable': 0.80,
            'critical': 0.70
        },
        'overall_weighted': {
            'excellent': 0.85,
            'acceptable': 0.75,
            'critical': 0.65
        }
    }
    
    current_scores = {
        'security_alert': 1.0000,
        'user_action': 0.9474,
        'overall_weighted': 0.8038
    }
    
    print("üéØ RECOMMENDED MONITORING THRESHOLDS:")
    
    for category, threshold in thresholds.items():
        current = current_scores.get(category, 0)
        print(f"\n   {category.replace('_', ' ').title()}:")
        print(f"      Current F1: {current:.4f}")
        
        if current >= threshold['excellent']:
            status = "‚úÖ EXCELLENT"
        elif current >= threshold['acceptable']:
            status = "‚ö†Ô∏è  ACCEPTABLE"
        elif current >= threshold['critical']:
            status = "‚ùå NEEDS ATTENTION"
        else:
            status = "üö® CRITICAL"
            
        print(f"      Status: {status}")
        print(f"      Thresholds: Excellent‚â•{threshold['excellent']}, "
              f"Acceptable‚â•{threshold['acceptable']}, "
              f"Critical<{threshold['critical']}")
    
    print(f"\nüîß MONITORING RECOMMENDATIONS:")
    print(f"   ‚Ä¢ Check F1 scores weekly in production")
    print(f"   ‚Ä¢ Retrain if security_alert F1 drops below 0.90")
    print(f"   ‚Ä¢ Investigate if overall weighted F1 drops below 0.75")
    print(f"   ‚Ä¢ Alert if any category drops 2 consecutive weeks")

def main():
    """Main analysis function"""
    print("üöÄ F1 Score Business Impact Analysis for Log Classification")
    
    # Analyze business impact
    savings = analyze_business_impact()
    
    # Explain F1 vs accuracy
    explain_f1_vs_accuracy()
    
    # Show monitoring thresholds
    show_monitoring_thresholds()
    
    print(f"\n‚úÖ SUMMARY:")
    print(f"   Your model's excellent F1 scores provide:")
    print(f"   üí∞ ${savings['annual_savings']:,} annual cost savings")
    print(f"   üõ°Ô∏è  {savings['security_threats_prevented']} fewer missed threats/month")
    print(f"   ‚è∞ {savings['false_alarms_reduced']:,} fewer false alarms/month")

if __name__ == "__main__":
    main()